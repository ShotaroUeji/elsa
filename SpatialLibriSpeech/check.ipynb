{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63fa3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['acoustics/c50_db', 'acoustics/drr_db', 'acoustics/edt_ms',\n",
      "       'acoustics/frequency_bins', 'acoustics/t20_ms', 'acoustics/t30_ms',\n",
      "       'audio_info/checksum/ambisonics',\n",
      "       'audio_info/checksum/noise_ambisonics', 'audio_info/duration',\n",
      "       'audio_info/frames', 'audio_info/size/ambisonics',\n",
      "       'audio_info/size/noise_ambisonics', 'lite_version', 'noise/azimuth',\n",
      "       'noise/deep_noise_suppression_metadata/filename',\n",
      "       'noise/deep_noise_suppression_metadata/is_audioset',\n",
      "       'noise/deep_noise_suppression_metadata/label',\n",
      "       'noise/deep_noise_suppression_metadata/youtube_id', 'noise/distance',\n",
      "       'noise/elevation', 'noise/snr', 'noise/source_id', 'room/floor_area',\n",
      "       'room/room_id', 'room/surface_area', 'room/volume', 'sample_id',\n",
      "       'speech/azimuth', 'speech/directivity_id', 'speech/distance',\n",
      "       'speech/elevation', 'speech/librispeech_metadata/book_id',\n",
      "       'speech/librispeech_metadata/chapter_id',\n",
      "       'speech/librispeech_metadata/chapter_title',\n",
      "       'speech/librispeech_metadata/project_id',\n",
      "       'speech/librispeech_metadata/project_title',\n",
      "       'speech/librispeech_metadata/reader_id',\n",
      "       'speech/librispeech_metadata/reader_name',\n",
      "       'speech/librispeech_metadata/reader_sex',\n",
      "       'speech/librispeech_metadata/sequence_number',\n",
      "       'speech/librispeech_metadata/subset',\n",
      "       'speech/librispeech_metadata/transcription', 'speech/mrp',\n",
      "       'speech/source_id', 'speech/speaking_azimuth',\n",
      "       'speech/speaking_elevation', 'split'],\n",
      "      dtype='object')\n",
      "2.1290625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_parquet(\"metadata.parquet\")\n",
    "print(meta.columns)       # 利用可能な項目を確認\n",
    "\n",
    "# 例: sample_id=0 の場合\n",
    "duration = meta.loc[meta.sample_id == 0, \"audio_info/duration\"].iloc[0]\n",
    "print(duration)  # 秒単位での長さ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0c5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    acoustics/c50_db  \\\n",
      "0  [-17.32041497023026, -16.359266083519866, -12....   \n",
      "1  [-16.021165970483054, -13.737698475512165, -12...   \n",
      "2  [-18.175496191222948, -17.306835853815034, -19...   \n",
      "3  [-17.508362813693353, -16.856860683549982, -14...   \n",
      "4  [-16.59338701427417, -15.792701167896723, -12....   \n",
      "\n",
      "                                    acoustics/drr_db  \\\n",
      "0  [-106.88784169381441, -96.21020819230088, -85....   \n",
      "1  [-94.556849284041, -82.3024077514615, -77.9493...   \n",
      "2  [-100.61744618815055, -90.97003289968285, -82....   \n",
      "3  [-110.41427074231669, -100.89350190121993, -92...   \n",
      "4  [-100.84837171985211, -90.97729274409367, -82....   \n",
      "\n",
      "                                    acoustics/edt_ms  \\\n",
      "0  [2341.8692574118872, 1894.8049907171328, 1874....   \n",
      "1  [2354.5006957921055, 1676.5186551918446, 1880....   \n",
      "2  [2341.2589960411165, 1970.2121309429288, 2809....   \n",
      "3  [2434.225849705927, 1803.1517151255453, 1873.0...   \n",
      "4  [2368.8539658235904, 1822.9932928347541, 1440....   \n",
      "\n",
      "                            acoustics/frequency_bins  \\\n",
      "0  [12.5, 16.0, 20.0, 25.0, 31.5, 40.0, 50.0, 63....   \n",
      "1  [12.5, 16.0, 20.0, 25.0, 31.5, 40.0, 50.0, 63....   \n",
      "2  [12.5, 16.0, 20.0, 25.0, 31.5, 40.0, 50.0, 63....   \n",
      "3  [12.5, 16.0, 20.0, 25.0, 31.5, 40.0, 50.0, 63....   \n",
      "4  [12.5, 16.0, 20.0, 25.0, 31.5, 40.0, 50.0, 63....   \n",
      "\n",
      "                                    acoustics/t20_ms  \\\n",
      "0  [1804.9543968723913, 1483.7479660572471, 1470....   \n",
      "1  [1897.1578972187287, 1495.102198672535, 1012.3...   \n",
      "2  [1872.3747070114, 1530.2266260726617, 1085.390...   \n",
      "3  [1538.562555467866, 1381.0252937440616, 1217.4...   \n",
      "4  [1210.8054920722118, 1414.6894117488912, 1232....   \n",
      "\n",
      "                                    acoustics/t30_ms  \\\n",
      "0  [1423.147784431817, 1532.1603002228992, 1254.0...   \n",
      "1  [1971.26739341687, 1590.8143324288797, 1000.24...   \n",
      "2  [1945.1715626637535, 1605.8743236520277, 1074....   \n",
      "3  [1449.9192933392342, 1116.1234079446383, 1064....   \n",
      "4  [1103.7162486188038, 1133.787491893144, 1162.6...   \n",
      "\n",
      "                      audio_info/checksum/ambisonics  \\\n",
      "0  c781f94c27d43c490ebb3b51da916e798c9cb4a2ae57c0...   \n",
      "1  11dfde67ed2dd5f1fce4df8056f4f7925edb232743303a...   \n",
      "2  e65c4a11fe8ba3978497c6f6e6bbccc9adf354e0183958...   \n",
      "3  87a44d487028a8fdc29143763c1a8c51bae1a5cd48892e...   \n",
      "4  a4d74d3854e6792719738d56fbb426c17e59f6f1726e88...   \n",
      "\n",
      "                audio_info/checksum/noise_ambisonics  audio_info/duration  \\\n",
      "0  5d2c3a22c572c682584507657849ce52142aa72ff6629c...             2.129062   \n",
      "1  588cc56b8f033cfe380dcd2e4d3d1cbce250acdfe24adb...             2.464562   \n",
      "2  d95657f19d6bbf864dc3cf7a785f8cfe4a8a732c5348a3...              3.14325   \n",
      "3  0bf9a308ee21fd7a69db3c48da849d52126c0346a275a5...             4.783375   \n",
      "4  894d4da3f8406ed10d6e4cdfda93f42c137924ebccaa38...             6.924812   \n",
      "\n",
      "   audio_info/frames  ...  speech/librispeech_metadata/reader_name  \\\n",
      "0              34065  ...                                Iridescat   \n",
      "1              39433  ...                              Katie Riley   \n",
      "2              50292  ...                                   Aldark   \n",
      "3              76534  ...                                Diapadion   \n",
      "4             110797  ...                        Jason Ingolfsland   \n",
      "\n",
      "   speech/librispeech_metadata/reader_sex  \\\n",
      "0                                       F   \n",
      "1                                       F   \n",
      "2                                       M   \n",
      "3                                       M   \n",
      "4                                       M   \n",
      "\n",
      "   speech/librispeech_metadata/sequence_number  \\\n",
      "0                                           17   \n",
      "1                                           19   \n",
      "2                                          102   \n",
      "3                                           10   \n",
      "4                                           19   \n",
      "\n",
      "   speech/librispeech_metadata/subset  \\\n",
      "0                     train-clean-360   \n",
      "1                     train-clean-360   \n",
      "2                     train-clean-360   \n",
      "3                     train-clean-360   \n",
      "4                     train-clean-360   \n",
      "\n",
      "           speech/librispeech_metadata/transcription  speech/mrp  \\\n",
      "0                   I WOULD NEVER HAVE LEFT HIM ONLY   89.234918   \n",
      "1  ON WHICH THE CARPENTERS HAD BEEN FOR SOME TIME...   89.336595   \n",
      "2  A SUSPENSION OF HOSTILITIES AGAINST A SENTENCE...   98.308778   \n",
      "3  THERE WAS A DULL THUD AND A RENDING AND RIVING...   96.430252   \n",
      "4  BEST OF ALL HE OUGHT TO IMAGINE HIS FELLOW GAM...    89.50104   \n",
      "\n",
      "  speech/source_id speech/speaking_azimuth  speech/speaking_elevation  split  \n",
      "0                1                0.527785                   0.025967  train  \n",
      "1                1                0.032463                  -0.039349  train  \n",
      "2                1               -1.288815                  -0.907462  train  \n",
      "3                1                2.548866                  -0.088185  train  \n",
      "4                1                1.479207                  -0.129298  train  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "print(meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f332b080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10秒以上のサンプル数: 143195\n",
      "        sample_id  audio_info/duration\n",
      "9               9            10.565687\n",
      "10             10            10.494063\n",
      "11             11               12.075\n",
      "12             12            10.440625\n",
      "14             14             11.61275\n",
      "...           ...                  ...\n",
      "221449     221449            18.259812\n",
      "221452     221452            11.477375\n",
      "221454     221454             28.85375\n",
      "221455     221455            20.457625\n",
      "221456     221456            19.699625\n",
      "\n",
      "[143195 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 10秒以上のサンプルを抽出\n",
    "filtered = meta[meta[\"audio_info/duration\"] >= 10]\n",
    "\n",
    "# サンプル数を表示\n",
    "print(\"10秒以上のサンプル数:\", len(filtered))\n",
    "\n",
    "# 必要に応じて一覧も表示\n",
    "print(filtered[[\"sample_id\", \"audio_info/duration\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7494cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_parquet(\"metadata.parquet\")\n",
    "\n",
    "# 10秒以上のものだけ\n",
    "meta_10s = meta[meta[\"audio_info/duration\"] >= 10]\n",
    "\n",
    "# 保存先フォルダ\n",
    "save_dir = \"./first10sec\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 音源が存在するフォルダ\n",
    "audio_dir = \"./preSpatialLibriSpeech\"\n",
    "\n",
    "# 新しいメタデータ格納用リスト\n",
    "new_metadata = []\n",
    "\n",
    "for idx, row in meta_10s.iterrows():\n",
    "    fname = f\"{idx:06d}.flac\"  # 6桁ゼロ埋めファイル名\n",
    "    path = os.path.join(audio_dir, fname)\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"{path}: ファイルが存在しません。スキップ\")\n",
    "        continue\n",
    "\n",
    "    # 音源読み込み\n",
    "    audio, sr = sf.read(path)\n",
    "    if audio.ndim != 2 or audio.shape[1] != 4:\n",
    "        print(f\"{fname}: 4ch(FOA)ではないのでスキップ\")\n",
    "        continue\n",
    "    if sr != 16000:\n",
    "        print(f\"{fname}: サンプリングレートが16kHzでないのでスキップ\")\n",
    "        continue\n",
    "\n",
    "    # 10秒分だけ抽出\n",
    "    audio_10s = audio[:160000, :]\n",
    "\n",
    "    # 新ファイルパス（ファイル名は元のまま＝index番号.flac）\n",
    "    out_path = os.path.join(save_dir, fname)\n",
    "    sf.write(out_path, audio_10s, sr, format='FLAC')\n",
    "\n",
    "    # 新しいメタデータ用辞書\n",
    "    row_new = row.copy()\n",
    "    row_new[\"audio_info/duration\"] = 10.0  # 長さを10.0に\n",
    "    new_metadata.append(row_new)\n",
    "\n",
    "# DataFrame化（index付きで）\n",
    "new_meta_df = pd.DataFrame(new_metadata, index=meta_10s.index)\n",
    "# 元のindexを維持したままCSV保存\n",
    "new_meta_df.to_csv(\"first10sec_metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818d8676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first10sec/000009.flac\n",
      "first10sec/000010.flac\n",
      "first10sec/000011.flac\n",
      "first10sec/000012.flac\n",
      "first10sec/000014.flac\n",
      "first10sec/000015.flac\n",
      "first10sec/000016.flac\n",
      "first10sec/000017.flac\n",
      "first10sec/000018.flac\n",
      "first10sec/000019.flac\n"
     ]
    }
   ],
   "source": [
    "ls first10sec/*.flac | head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bea0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([9, 10, 11, 12, 14], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/home/takamichi-lab-pc09/SpatialLibriSpeech/first10sec_metadata_zfilled.csv\", index_col=0)\n",
    "print(df.index[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ff9464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata側indexをゼロ詰め\n",
    "df = pd.read_csv(\"first10sec_metadata.csv\", index_col=0)\n",
    "df.index = df.index.map(lambda x: str(x).zfill(6))\n",
    "df.to_csv(\"first10sec_metadata_zfilled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abfbb208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 10, 11, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"first10sec_metadata.csv\", index_col=0)\n",
    "print(list(df.index[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74032e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"first10sec_metadata.csv\", index_col=0)\n",
    "df.index = df.index.map(lambda x: str(x).zfill(6))  # 6桁ゼロ詰め\n",
    "df.to_csv(\"first10sec_metadata_fixed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52a729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000014', '000024', '000017', '000019', '000018']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print([os.path.splitext(f)[0] for f in os.listdir(\"first10sec\")][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7eabf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 10, 11, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"first10sec_metadata_fixed.csv\", index_col=0)\n",
    "print(list(df.index[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f14a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> Index(['000009', '000010', '000011', '000012', '000014'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"first10sec_metadata.csv\", index_col=0)\n",
    "\n",
    "# indexをstrに変換してゼロ詰め\n",
    "df.index = df.index.map(lambda x: str(x).zfill(6))\n",
    "\n",
    "# 型がstrになっているかを確認\n",
    "print(type(df.index[0]), df.index[:5])\n",
    "\n",
    "# 文字列型のindexでCSV保存\n",
    "df.to_csv(\"first10sec_metadata_fixed.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9814b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 10, 11, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"first10sec_metadata_fixed.csv\", index_col=0, dtype={'index': str})\n",
    "print(list(df.index[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b353d69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 201, 1601]) torch.Size([3, 201, 1601]) torch.Size([44])\n"
     ]
    }
   ],
   "source": [
    "from foa_dataset import FOALabeledDataset\n",
    "\n",
    "ds = FOALabeledDataset(\"first10sec\", \"first10sec_metadata_fixed.csv\")\n",
    "I_act, I_rea, y = ds[0]\n",
    "print(I_act.shape, I_rea.shape, y.shape)   # (3,201,1601) (3,201,1601) (44,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32cf34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALAR_COLS = [\n",
    "  \"speech/azimuth\",\n",
    "  \"speech/elevation\",\n",
    "  \"speech/distance\",\n",
    "  \"room/volume\",\n",
    "]\n",
    "LIST_COLS = [\n",
    "  \"acoustics/drr_db\",\n",
    "  \"acoustics/t30_ms\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54bf3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 元CSV\n",
    "orig_csv = \"first10sec_metadata.csv\"\n",
    "# 抜き出すカラム\n",
    "use_cols = SCALAR_COLS + LIST_COLS\n",
    "\n",
    "# 読み込み時に usecols を指定する方法\n",
    "df = pd.read_csv(orig_csv, index_col=0, usecols=[\"Unnamed: 0\"] + use_cols)\n",
    "\n",
    "# 列名を揃えたらそのまま保存\n",
    "df.to_csv(\"first10sec_metadata_trimmed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6536d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min(std): nan max(std): nan\n",
      "any NaN in mean? False\n",
      "any NaN in  std ? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean = np.load(\"label_mean.npy\")\n",
    "std  = np.load(\"label_std.npy\")\n",
    "\n",
    "print(\"min(std):\", std.min(), \"max(std):\", std.max())\n",
    "print(\"any NaN in mean?\", np.isnan(mean).any())\n",
    "print(\"any NaN in  std ?\", np.isnan(std).any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5337b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRR+T30  mean ± std (1st 5 dims): [-103.97620987  -94.26289211  -85.28248339  -76.88478839  -68.7917131 ] [8.1505089  8.53076373 8.5444584  8.00855176 7.43740301]\n",
      "scalar   min_ : [39.506966  -3.1415434  0.4990865 -0.8447054] \n",
      "scalar   max_ : [9.517879e+02 3.141578e+00 4.023696e+00 8.529371e-01]\n"
     ]
    }
   ],
   "source": [
    "import joblib, numpy as np\n",
    "drt_sc  = joblib.load(\"fit/drt_scaler.joblib\")\n",
    "scl_sc  = joblib.load(\"fit/scalar_scaler.joblib\")\n",
    "\n",
    "print(\"DRR+T30  mean ± std (1st 5 dims):\",\n",
    "      drt_sc.mean_[:5], drt_sc.scale_[:5])\n",
    "print(\"scalar   min_ :\", scl_sc.data_min_, \"\\nscalar   max_ :\", scl_sc.data_max_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0a0479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRR/T30  ->  mean -0.0734  std 1.0689\n",
      "scalars  ->  min 0.125  max 0.636\n"
     ]
    }
   ],
   "source": [
    "import joblib, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "drt_sc  = joblib.load(\"fit/drt_scaler.joblib\")\n",
    "scl_sc  = joblib.load(\"fit/scalar_scaler.joblib\")\n",
    "\n",
    "def parse_arr(s):  # fit_scalers.py と同じ関数\n",
    "    import re\n",
    "    nums = re.findall(r\"[-+]?\\d+\\.?\\d*(?:e[-+]?\\d+)?\", s)\n",
    "    return np.asarray(nums, dtype=np.float32)\n",
    "\n",
    "df = pd.read_csv(\"trimmed＿first10sec_metadata.csv\")\n",
    "row  = df.sample(1).iloc[0]           # ランダム 1 行\n",
    "\n",
    "drr  = parse_arr(row[\"acoustics/drr_db\"])\n",
    "t30  = parse_arr(row[\"acoustics/t30_ms\"])\n",
    "sc   = np.array([row[\"room/volume\"],\n",
    "                 row[\"speech/azimuth\"],\n",
    "                 row[\"speech/distance\"],\n",
    "                 row[\"speech/elevation\"]], dtype=np.float32)\n",
    "\n",
    "# 変換\n",
    "x_drt = np.hstack([drr, t30]).reshape(1, -1)\n",
    "x_scl = sc.reshape(1, -1)\n",
    "\n",
    "z_drt = drt_sc.transform(x_drt)[0]\n",
    "z_scl = scl_sc.transform(x_scl)[0]\n",
    "\n",
    "print(\"DRR/T30  ->  mean {:.4f}  std {:.4f}\".format(z_drt.mean(), z_drt.std()))\n",
    "print(\"scalars  ->  min {:.3f}  max {:.3f}\".format(z_scl.min(), z_scl.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed8a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRR/T30  mean -0.383  std 0.547\n",
      "volume,distance  ->  [0.17957707 0.6135918 ]\n",
      "azimuth,elevation->  -0.1602724514273426 0.1019848178375966\n",
      "NaN or Inf?      ->  True\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np, re, torch\n",
    "\n",
    "# ---------- 事前に保存したスケーラをロード ----------\n",
    "drt_sc  = joblib.load(\"fit/drt_scaler.joblib\")       # DRR+T30 用 StandardScaler\n",
    "vd_sc   = joblib.load(\"fit/scalar_scaler.joblib\")    # volume+distance 用 MinMax\n",
    "\n",
    "# ---------- 1 行ランダムに取って検証 ----------\n",
    "df = pd.read_csv(\"/home/takamichi-lab-pc09/SpatialLibriSpeech/trimmed＿first10sec_metadata.csv\")\n",
    "\n",
    "def parse_arr(txt):\n",
    "    nums = re.findall(r\"[-+]?\\d+\\.?\\d*(?:e[-+]?\\d+)?\", txt.replace(\"\\n\",\" \"))\n",
    "    return np.asarray(nums, dtype=np.float32)\n",
    "\n",
    "row = df.sample(1).iloc[0]\n",
    "\n",
    "drr = parse_arr(row[\"acoustics/drr_db\"])\n",
    "t30 = parse_arr(row[\"acoustics/t30_ms\"])\n",
    "\n",
    "vol  = float(row[\"room/volume\"])\n",
    "dist = float(row[\"speech/distance\"])\n",
    "az   = float(row[\"speech/azimuth\"])\n",
    "el   = float(row[\"speech/elevation\"])\n",
    "\n",
    "# ---------- 正規化 ----------\n",
    "drt_norm   = drt_sc.transform(np.hstack([drr, t30])[None])[0]\n",
    "voldist_n  = vd_sc.transform(np.array([[vol, dist]], dtype=np.float32))[0]  # (vol_norm, dist_norm)\n",
    "\n",
    "# ---------- 結合（モデルと同順ならOK） ----------\n",
    "y_norm = np.concatenate([drt_norm, voldist_n, [az, el]])\n",
    "\n",
    "# ---------- 検証 ----------\n",
    "print(\"DRR/T30  mean {:.3f}  std {:.3f}\".format(drt_norm.mean(), drt_norm.std()))\n",
    "print(\"volume,distance  -> \", voldist_n)              # 0〜1 のはず\n",
    "print(\"azimuth,elevation-> \", az, el)                 # 元の度数そのまま\n",
    "print(\"NaN or Inf?      -> \", np.isfinite(y_norm).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9726a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mpython sanity_check.py metadata.csv scalers_dir/\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m戻り値 0 : 問題なし\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m戻り値 1 : NaN/Inf を含む行あり（行番号を表示）\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m csv_path, sc_dir = sys.argv[\u001b[32m1\u001b[39m], \u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m drt_sc  = joblib.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msc_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/drt_scaler.joblib\u001b[39m\u001b[33m\"\u001b[39m)      \u001b[38;5;66;03m# 40 dim\u001b[39;00m\n\u001b[32m     11\u001b[39m vd_sc   = joblib.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msc_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/scalar_scaler.joblib\u001b[39m\u001b[33m\"\u001b[39m)   \u001b[38;5;66;03m# 2 dim\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "python sanity_check.py metadata.csv scalers_dir/\n",
    "戻り値 0 : 問題なし\n",
    "戻り値 1 : NaN/Inf を含む行あり（行番号を表示）\n",
    "\"\"\"\n",
    "import sys, re, joblib, numpy as np, pandas as pd\n",
    "\n",
    "csv_path, sc_dir = sys.argv[1], sys.argv[2]\n",
    "drt_sc  = joblib.load(f\"{sc_dir}/drt_scaler.joblib\")      # 40 dim\n",
    "vd_sc   = joblib.load(f\"{sc_dir}/scalar_scaler.joblib\")   # 2 dim\n",
    "\n",
    "pat = re.compile(r\"[-+]?\\d+\\.?\\d*(?:e[-+]?\\d+)?\")\n",
    "def arr20(txt):                # 33→20 スライス\n",
    "    v = np.asarray([float(x) for x in pat.findall(txt.replace(\"\\n\",\" \"))], dtype=np.float32)\n",
    "    return v[9:29] if v.size==33 else None\n",
    "\n",
    "df = pd.read_csv(csv_path, dtype=str)\n",
    "bad_rows = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    drr = arr20(row[\"acoustics/drr_db\"])\n",
    "    t30 = arr20(row[\"acoustics/t30_ms\"])\n",
    "    if drr is None or t30 is None:\n",
    "        bad_rows.append(idx); continue\n",
    "\n",
    "    # --- スケール変換 ---\n",
    "    drt_norm = drt_sc.transform(np.hstack([drr, t30]).reshape(1,-1))[0]\n",
    "    vol  = float(row[\"room/volume\"]); dist = float(row[\"speech/distance\"])\n",
    "    vd_norm = vd_sc.transform([[vol, dist]])[0]\n",
    "\n",
    "    # --- NaN / Inf チェック ---\n",
    "    y = np.concatenate([[row[\"speech/azimuth\"], row[\"speech/elevation\"]],\n",
    "                        vd_norm, drt_norm])\n",
    "    if not np.isfinite(y).all():\n",
    "        bad_rows.append(idx)\n",
    "\n",
    "if bad_rows:\n",
    "    print(\"❌ 問題のある行: \", bad_rows[:20], \" ...\")   # 多い場合は先頭20だけ表示\n",
    "    sys.exit(1)\n",
    "print(\"✅ 全行 OK — NaN/Inf なし\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d37cfd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"trimmed＿first10sec_metadata.csv\")\n",
    "df = pd.read_csv(\"metadata_clean.csv\")\n",
    "orig_len = len(df)\n",
    "clean_len = len(df[df[\"acoustics/drr_db\"] != \"[]\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6008c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行インデックス: 13678 \n",
      "--- scalar ---\n",
      "room/volume 332.6302795410156\n",
      "speech/azimuth 0.0011599355045488\n",
      "speech/distance 2.377574990462681\n",
      "speech/elevation 0.0680211586246528\n",
      "\n",
      "--- drr_db / t30_ms （抜粋）---\n",
      "acoustics/drr_db \n",
      "  [-52.58389815, -47.59734406, -43.51650474, -35.83435949] ... len= 33\n",
      "acoustics/t30_ms \n",
      "  [649.4296119, 553.76746021, 603.9556307, 487.49688502] ... len= 33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "\n",
    "idx = 13678                                               # 問題の行番号\n",
    "pat = re.compile(r\"[-+]?\\d+\\.?\\d*(?:e[-+]?\\d+)?\")\n",
    "df = pd.read_csv(\"/home/takamichi-lab-pc09/SpatialLibriSpeech/metadata_clean.csv\", dtype=str)\n",
    "\n",
    "row = df.iloc[idx]\n",
    "print(\"行インデックス:\", idx, \"\\n--- scalar ---\")\n",
    "for c in [\"room/volume\",\"speech/azimuth\",\"speech/distance\",\"speech/elevation\"]:\n",
    "    print(c, row[c])\n",
    "\n",
    "print(\"\\n--- drr_db / t30_ms （抜粋）---\")\n",
    "for col in [\"acoustics/drr_db\", \"acoustics/t30_ms\"]:\n",
    "    nums = [float(x) for x in pat.findall(row[col].replace(\"\\n\",\" \"))]\n",
    "    print(col, \"\\n \", nums[8:12], \"...\", \"len=\", len(nums))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a1f2ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134682\n",
      "134683\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bad = [13678]                       # 問題行インデックス\n",
    "df = pd.read_csv(\"/home/takamichi-lab-pc09/SpatialLibriSpeech/trimmed＿first10sec_metadata.csv\")\n",
    "\n",
    "df_clean= pd.read_csv(\"metadata_clean.csv\")\n",
    "\n",
    "print(len(df_clean))  # 13679 - 1 = 13678\n",
    "print(len(df))  # 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff1373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
