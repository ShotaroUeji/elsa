#!/usr/bin/env python3
"""
ã€æœ€çµ‚ç‰ˆã€‘ä¸»è¦ãª3è¦–ç‚¹ã‹ã‚‰ã®é™æ­¢ç”»ã‚’ç”Ÿæˆã™ã‚‹ã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import numpy as np
import pyroomacoustics as pra
import math
from scipy.signal import fftconvolve
from pyroomacoustics.directivities import CardioidFamily, DirectionVector
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def visualize_key_views(mic_positions, source_pos, dirs, axis):
    """
    3ã¤ã®ä¸»è¦ãªè¦–ç‚¹ã‹ã‚‰é™æ­¢ç”»ã‚’ç”Ÿæˆã—ã€å‘ãã‚’æœ€çµ‚ç¢ºèªã™ã‚‹é–¢æ•°
    """
    # æç”»ã™ã‚‹è¦–ç‚¹ï¼ˆ elevation, azimuth ï¼‰ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆ
    views = {
        'diagonal': (30, 45),    # å…¨ä½“åƒãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã€æ–œã‚ã‹ã‚‰ã®è¦–ç‚¹
        'top_down': (90, 0),     # çœŸä¸Šã‹ã‚‰ã®è¦–ç‚¹
        'side_on':  (5, 270)     # ã»ã¼çœŸæ¨ªã‹ã‚‰ã®è¦–ç‚¹
    }

    for view_name, (elev, azim) in views.items():
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection='3d')

        # 1. éŸ³æº
        ax.scatter(source_pos[0], source_pos[1], source_pos[2], c='r', marker='*', s=200, label='Sound Source')

        # 2. ãƒã‚¤ã‚¯ã‚«ãƒ—ã‚»ãƒ«ã¨ç•ªå·
        ax.scatter(mic_positions[0, :], mic_positions[1, :], mic_positions[2, :], c='b', s=100, label='Mic Capsules')
        for i in range(mic_positions.shape[1]):
             ax.text(mic_positions[0, i], mic_positions[1, i], mic_positions[2, i], f' {i}', color='k')

        # 3. ã‚«ãƒ—ã‚»ãƒ«ã®å‘ã
        colors = ['cyan', 'magenta', 'yellow', 'lime']
        for i in range(mic_positions.shape[1]):
            pos = mic_positions[:, i]
            dv = dirs[i]._orientation
            az_rad, col_rad = np.deg2rad(dv._azimuth), np.deg2rad(dv._colatitude)
            dx = 0.4 * np.sin(col_rad) * np.cos(az_rad)
            dy = 0.4 * np.sin(col_rad) * np.sin(az_rad)
            dz = 0.4 * np.cos(col_rad)
            ax.quiver(pos[0], pos[1], pos[2], dx, dy, dz, color=colors[i])

        # ã‚°ãƒ©ãƒ•ã®è¦‹ãŸç›®ã‚’è¨­å®š
        ax.set_xlabel('X-Axis'); ax.set_ylabel('Y-Axis'); ax.set_zlabel('Z-Axis')
        ax.set_title(f"View: {view_name.replace('_', ' ').title()} | Source on {axis}-Axis")
        ax.legend()
        ax.view_init(elev=elev, azim=azim)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_filename = f"foa_geometry_{axis}_{view_name}.png"
        plt.savefig(output_filename)
        print(f"âœ… Image saved to '{output_filename}'")
        plt.close(fig)

def validate_foa_simulation(axis='X', visualize=False):
    print(f"\n--- ğŸ§ª Verifying {axis}-Axis ---")
    fs = 48000; room_dims = [10, 8, 6]
    wav_impulse = np.zeros(fs, dtype=np.float32); wav_impulse[100] = 1.0
    room = pra.ShoeBox(room_dims, fs=fs, max_order=0)
    mic_center = np.array(room_dims) / 2
    distance = 2.0
    if axis == 'X': source_pos = mic_center + np.array([distance, 0, 0])
    elif axis == 'Y': source_pos = mic_center + np.array([0, distance, 0])
    elif axis == 'Z': source_pos = mic_center + np.array([0, 0, distance])
    room.add_source(source_pos.tolist(), signal=wav_impulse)
    r = 0.05; v = r / math.sqrt(3)
    tet = np.array([[v,v,v], [v,-v,-v], [-v,v,-v], [-v,-v,v]], dtype=float).T
    dirs = []
    for x, y, z in tet.T:
        az, col = np.degrees(np.arctan2(y, x)) % 360, np.degrees(np.arccos(z / r))
        dirs.append(CardioidFamily(orientation=DirectionVector(azimuth=az, colatitude=col, degrees=True), p=0.5, gain=1.0))
    mic_positions = mic_center.reshape(3, 1) + tet
    
    if visualize:
        visualize_key_views(mic_positions, source_pos, dirs, axis)

    # (éŸ³éŸ¿è¨ˆç®—éƒ¨åˆ†ã¯çœç•¥ã—ã¦ã‚‚å¯è¦–åŒ–ã¯ã§ãã¾ã™)

if __name__ == "__main__":
    # Zè»¸ã®å¯è¦–åŒ–ã®ã¿ã‚’å®Ÿè¡Œã—ã¦ç¢ºèª
    validate_foa_simulation(axis='Z', visualize=True)